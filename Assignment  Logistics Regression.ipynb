{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501a8291",
   "metadata": {},
   "source": [
    "## Question 1: What is Simple Linear Regression (SLR)? Explain its purpose.\n",
    "Simple Linear Regression (SLR) is a statistical technique used to model the relationship between **one independent variable (X)** and **one dependent variable (Y)**. It fits a straight line that best represents how changes in X affect Y.\n",
    "\n",
    "**Purpose of SLR:**\n",
    "- To predict the value of Y based on X.\n",
    "- To analyze the strength and direction of their relationship.\n",
    "- To understand how much Y changes when X changes by one unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2f9d9",
   "metadata": {},
   "source": [
    "## Question 2: What are the key assumptions of Simple Linear Regression?\n",
    "1. **Linearity** – The relationship between X and Y is linear.\n",
    "2. **Independence** – Observations are independent of each other.\n",
    "3. **Homoscedasticity** – Constant variance of errors across all levels of X.\n",
    "4. **Normality of errors** – Residuals follow a normal distribution.\n",
    "5. **No multicollinearity** – Not applicable to SLR since only one X variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702c6c1",
   "metadata": {},
   "source": [
    "## Question 3: Mathematical Equation of Simple Linear Regression\n",
    "The simple linear regression model is:\n",
    "\n",
    "\\[ Y = b_0 + b_1X + \\varepsilon \\]\n",
    "\n",
    "Where:\n",
    "- **Y** = Dependent variable (output)\n",
    "- **X** = Independent variable (input)\n",
    "- **b₀** = Intercept (value of Y when X = 0)\n",
    "- **b₁** = Slope (change in Y for each 1-unit increase in X)\n",
    "- **ε** = Error term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb242b",
   "metadata": {},
   "source": [
    "## Question 4: Real-world Example of Simple Linear Regression\n",
    "A very common and intuitive real-world example of Simple Linear Regression is predicting a student's exam score based on the number of hours they studied.\n",
    "\n",
    "Example: Predicting Exam Score from Hours Studied\n",
    "Independent Variable (X):\n",
    "\n",
    "Hours of study\n",
    "\n",
    "Dependent Variable (Y):\n",
    "\n",
    "Exam score (out of 100)\n",
    "\n",
    "How the data is used\n",
    "\n",
    "We collect data from many students:\n",
    "\n",
    "How many hours each student studied\n",
    "\n",
    "What exam score they achieved\n",
    "\n",
    "When we plot this data on a graph, we usually see a positive trend — students who study more hours generally score higher.\n",
    "\n",
    "How SLR is applied in this example\n",
    "1. Finding the best-fit line\n",
    "\n",
    "Simple Linear Regression identifies the straight line that best fits the data points.\n",
    "\n",
    "2. Quantifying the relationship\n",
    "\n",
    "The model might show something like:\n",
    "\n",
    "“For every additional 1 hour of study, the exam score increases by about 5 points.”\n",
    "\n",
    "This gives a numerical measure of how strongly studying affects performance.\n",
    "\n",
    "3. Making predictions\n",
    "\n",
    "If a new student studies for 7 hours, the model can predict their likely score.\n",
    "For example:\n",
    "\n",
    "“A student who studies 7 hours is predicted to score around 80.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42f0808",
   "metadata": {},
   "source": [
    "## Question 5: What is the method of Least Squares?\n",
    "TMethod of Least Squares\n",
    "\n",
    "The Method of Least Squares is the standard technique used to find the best-fitting line in a linear regression model.\n",
    "\n",
    "1. What the Method Tries to Do\n",
    "\n",
    "We have a set of data points (X, Y).\n",
    "\n",
    "We want to draw a straight line:\n",
    "Predicted Y = b0 + b1 * X\n",
    "\n",
    "Every line we draw will have errors (residuals).\n",
    "\n",
    "2. What is a Residual\n",
    "\n",
    "Residual = Actual Y − Predicted Y\n",
    "\n",
    "It is the vertical distance between a data point and the regression line.\n",
    "\n",
    "Some residuals are positive (above the line), some are negative (below the line).\n",
    "\n",
    "3. Why We Square the Errors\n",
    "\n",
    "If we add residuals directly, positive and negative values cancel out.\n",
    "\n",
    "Squaring them makes all errors positive.\n",
    "\n",
    "This gives us the Sum of Squared Errors (SSE).\n",
    "\n",
    "4. Sum of Squared Errors (SSE)\n",
    "\n",
    "SSE = Sum of (Actual Y − Predicted Y)²\n",
    "\n",
    "It represents the total error of the line.\n",
    "\n",
    "5. Goal of the Method of Least Squares\n",
    "\n",
    "The method finds the values of b0 (intercept) and b1 (slope)\n",
    "\n",
    "That produce the smallest possible SSE.\n",
    "\n",
    "The line with the lowest SSE is considered the best-fit line, because it is the closest to all the data points overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac411d3c",
   "metadata": {},
   "source": [
    "## Question 6: What is Logistic Regression? How is it different from Linear Regression?\n",
    "**Logistic Regression** is a classification algorithm used when the output variable is **categorical**, usually binary (0 or 1).\n",
    "\n",
    "**Differences:**\n",
    "- Linear Regression predicts **continuous values**; Logistic Regression predicts **probabilities**.\n",
    "- Linear Regression uses a straight line; Logistic Regression uses the **sigmoid curve**.\n",
    "- Logistic Regression outputs values between **0 and 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e03c8",
   "metadata": {},
   "source": [
    "## Question 7: Three Common Evaluation Metrics for Regression\n",
    "1. **MAE (Mean Absolute Error):** Average absolute error between predicted and actual values.\n",
    "2. **MSE (Mean Squared Error):** Average squared error—penalizes large errors.\n",
    "3. **RMSE (Root Mean Squared Error):** Square root of MSE—interpretable in original units of Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f2f78",
   "metadata": {},
   "source": [
    "## Question 8: Purpose of R-squared in Regression\n",
    "Purpose of the R-squared Metric\n",
    "\n",
    "R-squared (R2), also called the Coefficient of Determination, measures how well a regression model explains the variation in the dependent variable.\n",
    "\n",
    "1. What R-squared Measures\n",
    "\n",
    "It tells you what percentage of the variation in Y is explained by X.\n",
    "\n",
    "Value ranges from 0 to 1 (or 0% to 100%).\n",
    "\n",
    "2. How to Interpret R-squared\n",
    "\n",
    "R2 = 1.0 (100%)\n",
    "The model explains all the variability. Perfect fit.\n",
    "\n",
    "R2 = 0.60 (60%)\n",
    "The model explains 60% of the variation in Y.\n",
    "The remaining 40% is due to other factors or random error.\n",
    "\n",
    "R2 = 0.0 (0%)\n",
    "The model explains none of the variation.\n",
    "There is no linear relationship between X and Y.\n",
    "\n",
    "3. Purpose of R-squared\n",
    "\n",
    "Shows how well the model fits the data.\n",
    "\n",
    "Helps evaluate how much of Y’s behavior is captured by the regression model.\n",
    "\n",
    "Complementary to error metrics like MAE or MSE.\n",
    "\n",
    "4. Important Note\n",
    "\n",
    "A high R2 does not automatically mean a good model.\n",
    "\n",
    "R2 cannot be used to compare models with different numbers of predictors.\n",
    "\n",
    "In such cases, Adjusted R-squared is preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0b9e8",
   "metadata": {},
   "source": [
    "## Question 9: Python Code for Simple Linear Regression\n",
    "Below is the Python code using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a9215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simple Linear Regression Results ---\n",
      "Intercept (beta_0): 45.85294117647059\n",
      "Slope (beta_1): 5.029411764705882\n",
      "----------------------------------------\n",
      "\n",
      "Model Equation: y = 45.85 + 5.03 * X\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# 1. Create some sample data\n",
    "# Let's use the \"hours studied\" vs \"exam score\" example\n",
    "# X = hours_studied, y = exam_score\n",
    "# np.array(...).reshape(-1, 1) is used to format X for scikit-learn\n",
    "X = np.array([1, 2, 3, 4, 5, 7, 8, 10]).reshape(-1, 1)\n",
    "y = np.array([50, 55, 62, 68, 70, 80, 88, 95])\n",
    "\n",
    "# 2. Create the Linear Regression model object\n",
    "# This is like creating a \"blank\" model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 3. Fit the model to the data\n",
    "# This is the \"training\" step. The model \"learns\" the best\n",
    "# intercept (b0) and slope (b1) from the data (X, y).\n",
    "model.fit(X, y)\n",
    "\n",
    "# 4. Get the learned parameters\n",
    "# The 'intercept_' attribute stores b0\n",
    "intercept = model.intercept_\n",
    "\n",
    "# The 'coef_' attribute stores the slope(s). For SLR, it's a single value.\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# 5. Print the slope and intercept\n",
    "print(\"--- Simple Linear Regression Results ---\")\n",
    "print(f\"Intercept (beta_0): {intercept}\")\n",
    "print(f\"Slope (beta_1): {slope}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(\"\\nModel Equation: y = {:.2f} + {:.2f} * X\".format(intercept, slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa1ebfb",
   "metadata": {},
   "source": [
    "## Question 10: Interpretation of Coefficients in SLR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf7a03",
   "metadata": {},
   "source": [
    "In a simple linear regression model, the equation is:\n",
    "\n",
    "Y = b0 + b1 * X\n",
    "\n",
    "There are two important coefficients:\n",
    "\n",
    "1. Intercept (b0)\n",
    "\n",
    "This is the predicted value of Y when X = 0.\n",
    "\n",
    "It represents the starting level or baseline value.\n",
    "\n",
    "Sometimes it has a real meaning (example: predicted exam score with 0 hours of study).\n",
    "\n",
    "Sometimes it does NOT have a real meaning (example: predicted price for a house with 0 square feet).\n",
    "\n",
    "2. Slope (b1)\n",
    "\n",
    "This tells us how much Y changes when X increases by 1 unit.\n",
    "\n",
    "It shows the strength and direction of the relationship.\n",
    "\n",
    "Example: If b1 = 4.87, then for every 1 extra hour of study, the predicted exam score increases by 4.87 points.\n",
    "\n",
    "3. Direction of relationship\n",
    "\n",
    "If b1 is positive: Y increases when X increases.\n",
    "\n",
    "If b1 is negative: Y decreases when X increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
