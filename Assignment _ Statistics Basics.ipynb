{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Basics Assignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1: Descriptive vs. Inferential Statistics\n",
    "What is the difference between descriptive statistics and inferential statistics? Explain with examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "The primary difference lies in their purpose:\n",
    "\n",
    "1.  **Descriptive Statistics**: Focuses on summarizing and describing the characteristics of a specific dataset. It seeks to describe **what the data is**.\n",
    "2.  **Inferential Statistics**: Focuses on using a sample of data to make predictions, draw conclusions, or generalize about a larger **population**. It seeks to infer **what the data means**.\n",
    "\n",
    "### Explanation and Examples\n",
    "\n",
    "| Feature | Descriptive Statistics | Inferential Statistics |\n",
    "| :--- | :--- | :--- |\n",
    "| **Purpose** | To organize, summarize, and present data. | To make generalizations, predictions, or inferences about a population from a sample. |\n",
    "| **Tools** | Mean, Median, Mode, Standard Deviation, Histograms, Box Plots. | Hypothesis Testing, Confidence Intervals, Regression Analysis. |\n",
    "| **Example** | Calculating the **average score** $(\\bar{x})$ of all students in a single class on a final exam. | Surveying a **random sample of 1,000 voters** and using the results to **predict** the winner of a national presidential election. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2: Sampling and Sampling Types\n",
    "What is sampling in statistics? Explain the differences between random and stratified sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "### What is Sampling?\n",
    "**Sampling** in statistics is the process of selecting a smaller, manageable subset (**sample**) of individuals or items from a larger group (**population**) in order to estimate the characteristics of the whole population. It's used because studying every single member of a large population is often too expensive or time-consuming.\n",
    "\n",
    "### Random vs. Stratified Sampling\n",
    "\n",
    "| Feature | Random Sampling (Simple Random Sampling) | Stratified Sampling |\n",
    "| :--- | :--- | :--- |\n",
    "| **Process** | Every individual in the population has an equal and independent chance of being selected. | The population is first divided into non-overlapping subgroups (called **strata**) based on shared characteristics (e.g., age, gender). A random sample is then drawn *from each* stratum. |\n",
    "| **Goal** | To ensure the sample is generally unbiased and representative of the whole population. | To guarantee that specific, important subgroups are adequately and proportionally represented in the final sample. |\n",
    "| **Best Used When** | The population is relatively homogeneous. | The population is heterogeneous (diverse), and representation from key subgroups is mandatory. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3: Mean, Median, and Mode\n",
    "Define mean, median, and mode. Explain why these measures of central tendency are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "### Definitions of Mean, Median, and Mode\n",
    "These are the primary **measures of central tendency**, used to find the \"typical\" or center value of a dataset.\n",
    "\n",
    "* **Mean** $(\\bar{x})$: The arithmetic **average**. Calculated by summing all values and dividing by the count of values ($n$): $$\\text{Mean} = \\frac{\\sum x}{n} $$\n",
    "* **Median**: The **middle value** in a dataset when it is ordered from least to greatest. If the dataset has an even number of values, the median is the average of the two middle numbers.\n",
    "* **Mode**: The value that appears **most frequently** in a dataset. A dataset can have one mode, multiple modes, or no mode at all.\n",
    "\n",
    "### Importance of Central Tendency\n",
    "These measures are crucial in data analysis for several reasons:\n",
    "\n",
    "* **Data Summarization**: They provide a single, easy-to-understand value that summarizes the entire dataset.\n",
    "* **Comparison**: They allow for quick comparison between different groups or time periods (e.g., comparing the mean productivity of two teams).\n",
    "* **Detecting Skewness**: Comparing the mean and median helps reveal the distribution's shape and asymmetry (skewness).\n",
    "* **Resilience to Outliers (Median)**: The median is **robust** to extreme outliers, making it a better measure of the \"typical\" value than the mean in skewed datasets (like housing prices or income)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 4: Skewness and Kurtosis\n",
    "Explain skewness and kurtosis. What does a positive skew imply about the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "### Skewness\n",
    "**Skewness** measures the **asymmetry** of a probability distribution, indicating how much the data deviates from a symmetrical bell-shaped curve (normal distribution).\n",
    "\n",
    "* **Zero Skew**: Perfectly symmetrical distribution (Mean $\\approx$ Median $\\approx$ Mode).\n",
    "* **Positive Skew (Right-Skew)**: The distribution has a long tail extending to the right (higher values).\n",
    "* **Negative Skew (Left-Skew)**: The distribution has a long tail extending to the left (lower values).\n",
    "\n",
    "### Kurtosis\n",
    "**Kurtosis** measures the **\"tailedness\"** of a distribution. It describes the shape of the tails and the peakedness, indicating the presence of **outliers**.\n",
    "\n",
    "* **High Kurtosis (Leptokurtic)**: Distribution has heavy/fat tails and a sharp peak, suggesting a higher probability of extreme values (outliers).\n",
    "* **Low Kurtosis (Platykurtic)**: Distribution has light/thin tails and a flatter peak.\n",
    "\n",
    "### Implication of a Positive Skew\n",
    "A **positive skew** implies that the majority of the data is clustered toward the lower values, but the distribution is stretched toward the high values by a few extreme observations (outliers).\n",
    "\n",
    "* **Order of Measures**: $\\text{Mode} < \\text{Median} < \\text{Mean}$. The mean is pulled to the right by the high outliers.\n",
    "* **Real-World Example**: Personal income. Most people earn a moderate salary (cluster on the left), but a few top earners make extremely high amounts (the long right tail, pulling the mean up)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 5: Mean, Median, and Mode Python Implementation\n",
    "Implement a Python program to compute the mean, median, and mode of a given list of numbers.\n",
    "\n",
    "```python\n",
    "numbers = [12, 15, 12, 18, 19, 12, 20, 22, 19, 19, 24, 24, 24, 26, 28]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Given Numbers: [12, 15, 12, 18, 19, 12, 20, 22, 19, 19, 24, 24, 24, 26, 28]\n",
      "------------------------------\n",
      "Mean:   19.6\n",
      "Median: 19.0\n",
      "Mode:   12\n"
     ]
    }
   ],
   "source": [
    "# Install required packages in the notebook environment (will be skipped if already installed)\n",
    "%pip install numpy scipy -q\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# The given list of numbers\n",
    "numbers = [12, 15, 12, 18, 19, 12, 20, 22, 19, 19, 24, 24, 24, 26, 28]\n",
    "\n",
    "# 1. Compute the Mean\n",
    "data_mean = np.mean(numbers)\n",
    "\n",
    "# 2. Compute the Median\n",
    "data_median = np.median(numbers)\n",
    "\n",
    "# 3. Compute the Mode\n",
    "# stats.mode returns the mode and its count. We access the mode value.\n",
    "mode_result = stats.mode(numbers, keepdims=True)\n",
    "data_mode = mode_result.mode[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Given Numbers: {numbers}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Mean:   {data_mean}\")\n",
    "print(f\"Median: {data_median}\")\n",
    "print(f\"Mode:   {data_mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 6: Covariance and Correlation Python Implementation\n",
    "Compute the covariance and correlation coefficient between the following two datasets provided as lists in Python:\n",
    "\n",
    "```python\n",
    "list_x=[10,20,30,40,50]\n",
    "list_y=[15,25,35,45,60]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_x: [10, 20, 30, 40, 50]\n",
      "list_y: [15, 25, 35, 45, 60]\n",
      "------------------------------\n",
      "Covariance:             287.50\n",
      "Correlation Coefficient: 0.9934\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The given datasets\n",
    "list_x = [10, 20, 30, 40, 50]\n",
    "list_y = [15, 25, 35, 45, 60]\n",
    "\n",
    "# Convert lists to NumPy arrays for calculation\n",
    "x = np.array(list_x)\n",
    "y = np.array(list_y)\n",
    "\n",
    "# 1. Compute Covariance\n",
    "# np.cov returns the covariance matrix. The covariance between x and y is the off-diagonal element (0, 1).\n",
    "covariance_matrix = np.cov(x, y)\n",
    "covariance = covariance_matrix[0, 1]\n",
    "\n",
    "# 2. Compute Correlation Coefficient (Pearson's r)\n",
    "# np.corrcoef returns the correlation coefficient matrix. The correlation between x and y is the off-diagonal element (0, 1).\n",
    "correlation_matrix = np.corrcoef(x, y)\n",
    "correlation_coefficient = correlation_matrix[0, 1]\n",
    "\n",
    "# Print the results\n",
    "print(f\"list_x: {list_x}\")\n",
    "print(f\"list_y: {list_y}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Covariance:             {covariance:.2f}\")\n",
    "print(f\"Correlation Coefficient: {correlation_coefficient:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 7: Boxplot and Outlier Identification\n",
    "Write a Python script to draw a boxplot for the following numeric list and identify its outliers. Explain the result.\n",
    "\n",
    "```python\n",
    "data = [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29, 35]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29, 35]\n",
      "------------------------------\n",
      "Q1 (25th percentile): 16.5\n",
      "Q3 (75th percentile): 23.5\n",
      "Interquartile Range (IQR): 7.0\n",
      "Lower Fence: 6.0\n",
      "Upper Fence: 34.0\n",
      "------------------------------\n",
      "Identified Outliers: [35]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# The given dataset\n",
    "data = [12, 14, 14, 15, 18, 19, 19, 21, 22, 22, 23, 23, 24, 26, 29, 35]\n",
    "\n",
    "# Create a boxplot (Visualization)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.boxplot(data)\n",
    "plt.title('Boxplot of Numeric Data')\n",
    "plt.ylabel('Values')\n",
    "plt.xticks([1], ['Data'])\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Outlier Identification (using the 1.5 * IQR rule)\n",
    "# Calculate Quartiles and IQR\n",
    "Q1 = np.percentile(data, 25)\n",
    "Q3 = np.percentile(data, 75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate Fence Boundaries\n",
    "lower_fence = Q1 - (1.5 * IQR)\n",
    "upper_fence = Q3 + (1.5 * IQR)\n",
    "\n",
    "# Identify Outliers\n",
    "outliers = [x for x in data if x < lower_fence or x > upper_fence]\n",
    "\n",
    "print(f\"Data: {data}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Q1 (25th percentile): {Q1}\")\n",
    "print(f\"Q3 (75th percentile): {Q3}\")\n",
    "print(f\"Interquartile Range (IQR): {IQR}\")\n",
    "print(f\"Lower Fence: {lower_fence}\")\n",
    "print(f\"Upper Fence: {upper_fence}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Identified Outliers: {outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Result\n",
    "The calculation uses the standard **$1.5 \\times \\text{IQR}$ rule** to identify outliers:\n",
    "\n",
    "* **Quartiles and IQR**: The first quartile ($Q1$) is 16.5, and the third quartile ($Q3$) is 23.5. The **Interquartile Range (IQR)** is $Q3 - Q1 = 7.0$. The box in the plot spans this range.\n",
    "* **Fences**: The fences define the limits for non-outlier data points.\n",
    "    * **Lower Fence**: $Q1 - (1.5 \\times \\text{IQR}) = 16.5 - 10.5 = 6.0$.\n",
    "    * **Upper Fence**: $Q3 + (1.5 \\times \\text{IQR}) = 23.5 + 10.5 = 34.0$.\n",
    "* **Outlier Identification**: Any data point outside the range $[6.0, 34.0]$ is an outlier. The value **35** is greater than the upper fence of 34.0, making it the single outlier in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 8: Covariance and Correlation for E-commerce Analysis\n",
    "You are working as a data analyst in an e-commerce company. The marketing team wants to know if there is a relationship between advertising spend and daily sales. Explain how you would use covariance and correlation to explore this relationship. Write Python code to compute the correlation between the two lists:\n",
    "\n",
    "```python\n",
    "advertising_spend = [200, 250, 300, 400, 500]\n",
    "daily_sales = [2200, 2450, 2750, 3200, 4000]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: Using Covariance and Correlation\n",
    "To explore the relationship between advertising spend and daily sales, you'd use **covariance** to find the direction of the relationship and **correlation** to determine its strength.\n",
    "\n",
    "#### Covariance\n",
    "* **Use**: Measures the **direction** of the linear relationship.\n",
    "* **Interpretation**: A **positive covariance** means that as advertising spend increases, sales tend to increase (a direct relationship).\n",
    "* **Limitation**: The magnitude of covariance is difficult to interpret because it depends on the units of the variables (dollars and dollars), so it is not useful for measuring strength.\n",
    "\n",
    "#### Correlation (Pearson's $r$)\n",
    "* **Use**: Measures both the **direction** and the **strength** of the linear relationship. This is the more crucial metric for the marketing team.\n",
    "* **Interpretation**: The value is standardized between $-1$ and $+1$:\n",
    "    * A value close to **$+1$** (e.g., 0.99) indicates an **extremely strong positive linear relationship** (high spend consistently leads to high sales).\n",
    "    * A value close to **$0$** indicates a very weak or no linear relationship.\n",
    "* **Advantage**: Since it's unitless, it provides a clear, comparable measure of the relationship's strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertising Spend: [200, 250, 300, 400, 500]\n",
      "Daily Sales: [2200, 2450, 2750, 3200, 4000]\n",
      "------------------------------\n",
      "Correlation Coefficient (r): 0.9932\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The given lists\n",
    "advertising_spend = [200, 250, 300, 400, 500]\n",
    "daily_sales = [2200, 2450, 2750, 3200, 4000]\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "spend_array = np.array(advertising_spend)\n",
    "sales_array = np.array(daily_sales)\n",
    "\n",
    "# Compute the correlation coefficient (Pearson's r)\n",
    "# np.corrcoef returns the correlation coefficient matrix. We extract the off-diagonal element (0, 1).\n",
    "correlation_matrix = np.corrcoef(spend_array, sales_array)\n",
    "correlation_coefficient = correlation_matrix[0, 1]\n",
    "\n",
    "# Print the result\n",
    "print(f\"Advertising Spend: {advertising_spend}\")\n",
    "print(f\"Daily Sales: {daily_sales}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Correlation Coefficient (r): {correlation_coefficient:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: A correlation coefficient of **$0.9932$** indicates an extremely strong positive linear relationship between advertising spend and daily sales. The marketing spend is highly effective in driving sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 9: Analyzing Survey Data Distribution\n",
    "Your team has collected customer satisfaction survey data on a scale of 1-10 and wants to understand its distribution before launching a new product. Explain which summary statistics and visualizations (e.g. mean, standard deviation, histogram) you'd use. Write Python code to create a histogram using Matplotlib for the survey data:\n",
    "\n",
    "```python\n",
    "survey_scores=[7,8,5,9,6,7,8,9,10,4,7,6,9,8,7]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: Summary Statistics and Visualizations\n",
    "To thoroughly understand the customer satisfaction data, we would use a combination of descriptive statistics to quantify the center and spread, and a histogram for a visual assessment of the distribution's shape.\n",
    "\n",
    "#### Summary Statistics\n",
    "* **Mean and Median**: To determine the **average (typical)** satisfaction score. Comparing them helps check for any skew in customer responses.\n",
    "* **Standard Deviation $(\\sigma)$**: The key measure of **spread**. A low $\\sigma$ means customers largely agree on satisfaction, while a high $\\sigma$ suggests polarized opinions (many low and many high scores).\n",
    "\n",
    "#### Visualizations\n",
    "* **Histogram**: The most effective visual tool for understanding distribution. It shows the **frequency** of each score, immediately revealing the overall shape: is it generally high-scoring, skewed low, or perhaps bimodal (two peaks, indicating two distinct customer groups)?\n",
    "* **Box Plot**: Used to quickly summarize the five-number summary and visually identify any unusually low or high scores (outliers) in satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey Scores: [7, 8, 5, 9, 6, 7, 8, 9, 10, 4, 7, 6, 9, 8, 7]\n",
      "------------------------------\n",
      "Mean Score: 7.33\n",
      "Standard Deviation: 1.63\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# The given survey scores\n",
    "survey_scores = [7, 8, 5, 9, 6, 7, 8, 9, 10, 4, 7, 6, 9, 8, 7]\n",
    "\n",
    "# Calculate mean and standard deviation for reporting\n",
    "data_mean = np.mean(survey_scores)\n",
    "data_std = np.std(survey_scores)\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "# Define bins to ensure each whole score (4-10) has its own clear bar\n",
    "bins = np.arange(min(survey_scores) - 0.5, max(survey_scores) + 1.5, 1)\n",
    "\n",
    "plt.hist(survey_scores, bins=bins, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Customer Satisfaction Survey Scores (1-10)')\n",
    "plt.xlabel('Satisfaction Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(np.arange(4, 11, 1)) # Label x-axis for each score value\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Survey Scores: {survey_scores}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Mean Score: {data_mean:.2f}\")\n",
    "print(f\"Standard Deviation: {data_std:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
