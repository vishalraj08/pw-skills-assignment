{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Foundations of Machine Learning and \n",
        "EDA| Assignment "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 1: AI vs. ML vs. DL vs. Data Science\n",
        "> (Hint: Compare their scope, techniques, and applications for each.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "* **Artificial Intelligence (AI):** The broad concept of creating systems that simulate human intelligence (e.g., reasoning, problem-solving). It's the overall umbrella.\n",
        "    * **Applications:** Virtual assistants, game-playing engines.\n",
        "\n",
        "* **Machine Learning (ML):** A **subset of AI**. An *approach* where systems learn patterns from data, rather than being explicitly programmed.\n",
        "    * **Applications:** Spam filters, recommendation engines.\n",
        "\n",
        "* **Deep Learning (DL):** A specialized **subset of ML** that uses multi-layered neural networks to solve complex problems.\n",
        "    * **Applications:** Self-driving cars, image recognition, language translation.\n",
        "\n",
        "* **Data Science:** An interdisciplinary field that **uses** ML, DL, stats, and domain expertise to extract insights from data. It's the entire process (collection, cleaning, analysis, modeling).\n",
        "    * **Applications:** Business strategy, scientific research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 2: Overfitting and Underfitting\n",
        "> (Hint: Discuss bias-variance tradeoff, cross-validation, and regularization techniques.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "### Overfitting\n",
        "* **What it is:** The model learns the training data *too well*, capturing noise. It fails to generalize to new, unseen data.\n",
        "* **Symptoms:** High accuracy on training data, low accuracy on test data.\n",
        "* **Bias-Variance:** Low Bias, **High Variance**.\n",
        "* **Prevention:** \n",
        "    1.  **Regularization:** (L1/L2) Adds a penalty for complex models.\n",
        "    2.  **Get More Data:** Helps learn the true underlying pattern.\n",
        "    3.  **Simplify Model:** Use a less complex algorithm.\n",
        "\n",
        "### Underfitting\n",
        "* **What it is:** The model is *too simple* to capture the underlying pattern. It fails on both training and test data.\n",
        "* **Symptoms:** Low accuracy on *both* training and test data.\n",
        "* **Bias-Variance:** **High Bias**, Low Variance.\n",
        "* **Prevention:** \n",
        "    1.  **Use a More Complex Model:** e.g., move from linear to polynomial regression.\n",
        "    2.  **Feature Engineering:** Add more informative features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 3: Handling Missing Values\n",
        "> (Hint: Consider deletion, mean/median imputation, and predictive modeling.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "### 1. Deletion (Listwise/Row Deletion)\n",
        "* **Explanation:** Remove entire rows (or columns) that contain missing values.\n",
        "* **Pros:** Simple.\n",
        "* **Cons:** Can cause significant data loss and introduce bias.\n",
        "\n",
        "### 2. Mean/Median/Mode Imputation\n",
        "* **Explanation:** Replace missing values with the central tendency of that feature.\n",
        "    * **Mean:** For normally distributed numerical data.\n",
        "    * **Median:** For skewed numerical data (robust to outliers).\n",
        "    * **Mode:** For categorical data.\n",
        "* **Pros:** Simple, preserves data size.\n",
        "* **Cons:** Reduces variance and distorts relationships between features.\n",
        "\n",
        "### 3. Predictive Modeling (e.g., KNN or Regression Imputation)\n",
        "* **Explanation:** Use other features to predict the missing value. A KNN imputer finds similar rows and averages them; a regression imputer trains a model to predict the value.\n",
        "* **Pros:** More accurate; preserves relationships between features.\n",
        "* **Cons:** Computationally expensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 4: Imbalanced Dataset\n",
        "> (Hint: Discuss SMOTE, Random Under/Oversampling, and class weights in models.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "An **imbalanced dataset** is one where classes are not equally represented (e.g., 99% non-fraud, 1% fraud). This biases models toward the majority class.\n",
        "\n",
        "### 1. Random Oversampling\n",
        "* **Theoretical:** Duplicates random samples from the minority class to balance the dataset. This is done *only* on the training set.\n",
        "* **Practical (`imblearn`):**\n",
        "    ```python\n",
        "    from imblearn.over_sampling import RandomOverSampler\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "    ```\n",
        "* **Con:** Can lead to overfitting.\n",
        "\n",
        "### 2. SMOTE (Synthetic Minority Over-sampling TEchnique)\n",
        "* **Theoretical:** Intelligently creates *new synthetic* samples for the minority class. It finds a minority sample, picks one of its k-nearest minority neighbors, and creates a new sample on the line segment between them.\n",
        "* **Practical (`imblearn`):**\n",
        "    ```python\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
        "    ```\n",
        "* **Pro:** Creates new, plausible data, which generalizes better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 5: Feature Scaling\n",
        "> (Hint: Explain impact on distance-based algorithms (e.g., KNN, SVM) and gradient descent.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "**Feature scaling** is crucial because many algorithms are sensitive to the range of the data:\n",
        "\n",
        "1.  **Distance-Based Algorithms (KNN, SVM):** These algorithms calculate distances. A feature with a large range (e.g., 'Salary' 30k-150k) will dominate one with a small range (e.g., 'Age' 20-70). Scaling brings all features to a common ground.\n",
        "2.  **Gradient Descent (Linear Regression, Neural Networks):** Scaling helps the algorithm converge much faster. Unscaled features create an elongated, narrow loss surface, forcing the algorithm to take a slow, zig-zag path to the minimum.\n",
        "\n",
        "### Comparison\n",
        "\n",
        "| Feature | Min-Max Scaling (Normalization) | Standardization (Z-score Scaling) |\n",
        "| :--- | :--- | :--- |\n",
        "| **Formula** | `$X_{\\text{scaled}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}$` | `$X_{\\text{scaled}} = \\frac{X - \\mu}{\\sigma}$` |\n",
        "| **Output Range** | Fixed range, typically **[0, 1]**. | Mean of **0** and Std. Dev. of **1**. Not bounded. |\n",
        "| **Outliers** | **Very sensitive.** An outlier will squash all other data. | **Robust.** Outliers are scaled but don't dramatically affect other points. |\n",
        "| **When to Use** | Neural networks, image data. | **Default choice.** Most algorithms (SVM, KNN), especially if data has outliers. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 6: Label Encoding vs. One-Hot Encoding\n",
        "> (Hint: Consider categorical variables with ordinal vs. nominal relationships.)\n",
        "\n",
        "**Answer:**\n",
        "\n",
        "### Label Encoding\n",
        "* **What it does:** Assigns a unique integer to each category (e.g., `['Cold', 'Warm', 'Hot']` -> `[0, 1, 2]`).\n",
        "* **Problem:** It creates an *arbitrary* order. The model thinks `Hot (2) > Warm (1)`.\n",
        "* **When to use:** **Ordinal Data** (categories have a natural order). \n",
        "    * *Example:* `['Small', 'Medium', 'Large']` -> `[0, 1, 2]`. This is perfect because the numerical order matches the real-world order.\n",
        "\n",
        "### One-Hot Encoding\n",
        "* **What it does:** Creates a new binary (0/1) column for each category.\n",
        "    * *Example:* `['USA', 'India']` becomes two columns: `is_USA` and `is_India`.\n",
        "* **Problem:** Can create too many columns (curse of dimensionality).\n",
        "* **When to use:** **Nominal Data** (categories have no intrinsic order).\n",
        "    * *Example:* `['USA', 'India', 'Germany']`. This prevents the model from learning a false relationship like `Germany > USA`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 7: Google Play Store Dataset\n",
        "> a). Analyze the relationship between app categories and ratings. Which categories have the highest/lowest average ratings, and what could be the possible reasons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Analysis of App Ratings by Category ---\n",
            "\n",
            "Top 5 Highest Rated Categories:\n",
            "Category\n",
            "EVENTS                 4.435556\n",
            "EDUCATION              4.389032\n",
            "ART_AND_DESIGN         4.358065\n",
            "BOOKS_AND_REFERENCE    4.346067\n",
            "PERSONALIZATION        4.335987\n",
            "Name: Rating, dtype: float64\n",
            "\n",
            "Top 5 Lowest Rated Categories:\n",
            "Category\n",
            "VIDEO_PLAYERS           4.063750\n",
            "MAPS_AND_NAVIGATION     4.051613\n",
            "TOOLS                   4.047411\n",
            "TRAVEL_AND_LOCAL        4.039577\n",
            "DATING                  3.970769\n",
            "Name: Rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "try:\n",
        "    data_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/googleplaystore.csv'\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    # --- Data Cleaning ---\n",
        "    df = df.dropna(subset=['Rating'])\n",
        "    df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
        "    df = df.dropna(subset=['Rating'])\n",
        "    df = df[(df['Rating'] >= 1) & (df['Rating'] <= 5)]\n",
        "\n",
        "    # --- Analysis ---\n",
        "    category_ratings = df.groupby('Category')['Rating'].mean().sort_values(ascending=False)\n",
        "\n",
        "    # --- Visualization ---\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x=category_ratings.values, y=category_ratings.index, palette='viridis')\n",
        "    plt.title('Average App Rating by Category', fontsize=16)\n",
        "    plt.xlabel('Average Rating', fontsize=12)\n",
        "    plt.ylabel('App Category', fontsize=12)\n",
        "    plt.xlim(0, 5)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Print Highest and Lowest ---\n",
        "    print(\"--- Analysis of App Ratings by Category ---\")\n",
        "    print(\"\\nTop 5 Highest Rated Categories:\")\n",
        "    print(category_ratings.head(5))\n",
        "\n",
        "    print(\"\\nTop 5 Lowest Rated Categories:\")\n",
        "    print(category_ratings.tail(5))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "1.  **Highest Rated Categories:**\n",
        "    * **Categories:** `EVENTS`, `EDUCATION`, `ART_AND_DESIGN` (all > 4.35).\n",
        "    * **Reason:** These apps serve specific, functional, or niche purposes. Users who seek them out find them valuable, and satisfaction is high when they work as intended.\n",
        "\n",
        "2.  **Lowest Rated Categories:**\n",
        "    * **Categories:** `DATING`, `TRAVEL_AND_LOCAL`, `TOOLS`.\n",
        "    * **Reason:** `DATING` is highly subjective and success is tied to personal experience. `TOOLS` and `MAPS` have extremely high reliability expectations; a single bug or wrong turn leads to severe user frustration and 1-star reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 8: Titanic Dataset\n",
        "> a) Compare the survival rates based on passenger class (Pclass).\n",
        "> b) Analyze how age (Age) affected survival. Group passengers into children $(Age<18)$ and adults $(Age\\ge18)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Part (a): Survival Rate by Passenger Class ---\n",
            "Pclass\n",
            "1    62.962963\n",
            "2    47.282609\n",
            "3    24.236253\n",
            "Name: Survived, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Part (b): Survival Rate by Age Group ---\n",
            "AgeGroup\n",
            "Adult    36.116235\n",
            "Child    50.359712\n",
            "Name: Survived, dtype: float64\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "try:\n",
        "    data_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/titanic_train.csv'\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    # --- Part a: Analysis by Passenger Class (Pclass) ---\n",
        "    print(\"--- Part (a): Survival Rate by Passenger Class ---\")\n",
        "    pclass_survival = df.groupby('Pclass')['Survived'].mean() * 100\n",
        "    print(pclass_survival)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.barplot(x=pclass_survival.index, y=pclass_survival.values, palette='plasma')\n",
        "    plt.title('Survival Rate by Passenger Class (Pclass)', fontsize=16)\n",
        "    plt.xlabel('Passenger Class')\n",
        "    plt.ylabel('Survival Rate (%)')\n",
        "    plt.xticks([0, 1, 2], ['1st Class', '2nd Class', '3rd Class'])\n",
        "    plt.show()\n",
        "\n",
        "    # --- Part b: Analysis by Age Group (Children vs. Adults) ---\n",
        "    print(\"\\n--- Part (b): Survival Rate by Age Group ---\")\n",
        "    \n",
        "    # Impute missing 'Age' with median for this analysis\n",
        "    df['Age_Filled'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "    # Create Age Groups\n",
        "    df['AgeGroup'] = df['Age_Filled'].apply(lambda x: 'Child' if x < 18 else 'Adult')\n",
        "    \n",
        "    age_survival = df.groupby('AgeGroup')['Survived'].mean() * 100\n",
        "    print(age_survival)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    sns.barplot(x=age_survival.index, y=age_survival.values, palette='coolwarm')\n",
        "    plt.title('Survival Rate: Children vs. Adults', fontsize=16)\n",
        "    plt.xlabel('Age Group')\n",
        "    plt.ylabel('Survival Rate (%)')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "**Part a) Passenger Class and Survival:**\n",
        "**1st Class passengers had the highest survival rate (approx. 63%)**, followed by 2nd Class (47%) and 3rd Class (24%).\n",
        "* **Reason:** This reflects the socio-economic hierarchy. 1st Class cabins were on upper decks, closer to the lifeboats, and were given priority during the evacuation.\n",
        "\n",
        "**Part b) Age and Survival:**\n",
        "Yes, **children (under 18) had a significantly better chance of survival** (approx. 50%) compared to adults (approx. 36%).\n",
        "* **Reason:** This indicates the \"women and children first\" protocol was followed to some extent during the evacuation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 9: Flight Price Prediction Dataset\n",
        "> a) How do flight prices vary with the days left until departure? Identify any exponential price surges and recommend the best booking window.\n",
        "> b) Compare prices across airlines for the same route (e.g., Delhi-Mumbai)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Part (a): Price vs. Days Left Until Departure ---\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Part (b): Airline Price Comparison for Delhi-Mumbai Route ---\n",
            "Average Flight Prices (Delhi-Mumbai):\n",
            "airline\n",
            "SpiceJet    5194.022727\n",
            "Indigo      5294.380851\n",
            "Go_First    5413.529851\n",
            "Air_India   7698.860177\n",
            "Vistara     8385.297468\n",
            "Name: price, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "try:\n",
        "    data_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/flight_price_prediction.csv'\n",
        "    df = pd.read_csv(data_url)\n",
        "\n",
        "    # --- Part a: Price vs. Days Left Until Departure ---\n",
        "    print(\"--- Part (a): Price vs. Days Left Until Departure ---\")\n",
        "    days_left_price = df.groupby('days_left')['price'].mean()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.lineplot(x=days_left_price.index, y=days_left_price.values)\n",
        "    plt.title('Average Flight Price vs. Days Until Departure', fontsize=16)\n",
        "    plt.xlabel('Days Left Until Departure')\n",
        "    plt.ylabel('Average Price')\n",
        "    plt.gca().invert_xaxis() # Show time moving left-to-right\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.show()\n",
        "\n",
        "    # --- Part b: Airline Price Comparison (Delhi-Mumbai) ---\n",
        "    print(\"\\n--- Part (b): Airline Price Comparison for Delhi-Mumbai Route ---\")\n",
        "    route_df = df[(df['source'] == 'Delhi') & (df['destination'] == 'Mumbai')]\n",
        "\n",
        "    if route_df.empty:\n",
        "        print(\"No data found for the Delhi-Mumbai route.\")\n",
        "    else:\n",
        "        airline_prices = route_df.groupby('airline')['price'].mean().sort_values()\n",
        "        print(\"Average Flight Prices (Delhi-Mumbai):\")\n",
        "        print(airline_prices)\n",
        "\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        sns.boxplot(x='airline', y='price', data=route_df, palette='muted')\n",
        "        plt.title('Flight Price Distribution by Airline (Delhi-Mumbai)', fontsize=16)\n",
        "        plt.xlabel('Airline')\n",
        "        plt.ylabel('Price')\n",
        "        plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "**Part a) Price vs. Days Left:**\n",
        "* **Trend:** Prices are stable and low when booking >20 days in advance. Inside the 20-day window, prices climb, with a clear **exponential surge in the last 7-10 days**.\n",
        "* **Recommendation:** The **best booking window is 3 to 6 weeks (21-42 days) in advance**.\n",
        "\n",
        "**Part b) Airline Price Comparison (Delhi-Mumbai):**\n",
        "* **Budget Airlines:** `SpiceJet`, `Indigo`, and `Go_First` are consistently cheaper, with similar average prices. This is due to their low-cost carrier (LCC) model (no-frills service).\n",
        "* **Premium Airlines:** `Air_India` and `Vistara` are significantly more expensive. These are full-service carriers (FSCs) that include meals, baggage, and better service in the base price."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Question 10: HR Analytics Dataset\n",
        "> a). What factors most strongly correlate with employee attrition? Use visualizations to show key drivers (e.g., satisfaction, overtime, salary).\n",
        "> b). Are employees with more projects more likely to leave?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Part (a): Key Drivers of Employee Attrition ---\n",
            "\n",
            "Correlation with Attrition (1 = Left):\n",
            "Attrition                1.000000\n",
            "time_spend_company       0.144822\n",
            "average_montly_hours     0.071287\n",
            "number_project           0.023787\n",
            "salary_numeric          -0.157898\n",
            "Work_accident           -0.154622\n",
            "promotion_last_5years   -0.061788\n",
            "satisfaction_level      -0.388375\n",
            "Name: Attrition, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1800x500 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Part (b): Attrition Rate by Number of Projects ---\n",
            "number_project\n",
            "2     65.686275\n",
            "3      1.933702\n",
            "4      9.112172\n",
            "5     12.195122\n",
            "6     55.555556\n",
            "7    100.000000\n",
            "Name: Attrition, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "try:\n",
        "    data_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/HR_Analytics.csv'\n",
        "    df = pd.read_csv(data_url)\n",
        "    \n",
        "    df = df.rename(columns={'left': 'Attrition'})\n",
        "\n",
        "    # --- Part a: Factors Correlating with Attrition ---\n",
        "    print(\"--- Part (a): Key Drivers of Employee Attrition ---\")\n",
        "\n",
        "    # For correlation, map 'salary' to numeric\n",
        "    df['salary_numeric'] = df['salary'].map({'low': 0, 'medium': 1, 'high': 2})\n",
        "    \n",
        "    # Select only numeric columns for correlation\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64', 'int32'])\n",
        "    corr_matrix = numeric_cols.corr()\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
        "    plt.title('Correlation Heatmap of HR Analytics Features', fontsize=16)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\nCorrelation with Attrition (1 = Left):\")\n",
        "    print(corr_matrix['Attrition'].sort_values(ascending=False))\n",
        "    \n",
        "    # --- Visualize Key Drivers ---\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "    # 1. Satisfaction Level\n",
        "    sns.boxplot(ax=axes[0], x='Attrition', y='satisfaction_level', data=df, palette='pastel')\n",
        "    axes[0].set_title('Satisfaction Level vs. Attrition')\n",
        "    axes[0].set_xticklabels(['Stayed', 'Left'])\n",
        "\n",
        "    # 2. Salary\n",
        "    salary_attrition = df.groupby('salary')['Attrition'].mean().reset_index().sort_values(by='salary_numeric')\n",
        "    sns.barplot(ax=axes[1], x='salary', y='Attrition', data=salary_attrition, palette='Blues_r')\n",
        "    axes[1].set_title('Attrition Rate by Salary')\n",
        "    axes[1].set_ylabel('Attrition Rate (0 to 1)')\n",
        "\n",
        "    # 3. Average Monthly Hours\n",
        "    sns.kdeplot(ax=axes[2], data=df, x='average_montly_hours', hue='Attrition', fill=True, common_norm=False)\n",
        "    axes[2].set_title('Distribution of Avg. Monthly Hours')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # --- Part b: Number of Projects vs. Attrition ---\n",
        "    print(\"\\n--- Part (b): Attrition Rate by Number of Projects ---\")\n",
        "    project_attrition = df.groupby('number_project')['Attrition'].mean() * 100\n",
        "    print(project_attrition)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.barplot(x=project_attrition.index, y=project_attrition.values, palette='rocket')\n",
        "    plt.title('Attrition Rate (%) by Number of Projects', fontsize=16)\n",
        "    plt.xlabel('Number of Projects')\n",
        "    plt.ylabel('Attrition Rate (%)')\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis and Interpretation:**\n",
        "\n",
        "**Part a) Key Drivers of Attrition:**\n",
        "1.  **Satisfaction Level (Strongest Factor):** This has the strongest *negative* correlation (-0.39). The boxplot shows employees who left (`Attrition = 1`) had significantly lower satisfaction.\n",
        "2.  **Salary:** Employees with **low salaries** have a much higher attrition rate (nearly 30%) than those with high salaries (<10%).\n",
        "3.  **Average Monthly Hours:** The KDE plot shows employees who left are often in two groups: **under-worked** (boredom, ~140 hrs/mo) or **over-worked** (burnout, ~250+ hrs/mo).\n",
        "\n",
        "**Part b) Number of Projects vs. Attrition:**\n",
        "No, it's not a simple \"more projects = more likely to leave\" relationship. It's a **U-shaped curve**:\n",
        "\n",
        "* **Low Projects (2):** Very high attrition (66%). This suggests **boredom** or being sidelined.\n",
        "* **Medium Projects (3-5):** This is the \"stable\" zone with the lowest attrition rates.\n",
        "* **High Projects (6-7):** Attrition skyrockets (56% for 6, 100% for 7). This clearly indicates **burnout**."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
